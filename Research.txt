DeepPoseKit
>Single pose estimation
>>Image contains single individual, may be cropped from larger multi-individual image after localization and tracking
>>simplifies pose detection, does not require computationally expensive peak detection for grouping keypoints into indivual posture graphs
>>More found **Insafutdinov et al 2016, Cao et al 2017**

>Localization and tracking of individuals increases processing time of raw data
>>Automated tracking algorithms removes the labor intensive annotating process
>>Removes the need for linking posture data across multiple frames for tracking 

>Developed two model implementations
>>New model architecture -> Stacked DenseNet
>>New method for processing confidence maps -> subpixel maxima
>>>provides fast accurate peak detection for estimating keypoints
>>>Subpixel precision even at low spatial resolutions

>Discuss modification to incorporate hierarchical posture graph for learning geometry between keypoints on animals body, increasing accuacy.
>Model uses fewer parameters than DeepLabCut and LEAP

>Models description
>>First
>>>Novel implementaiton of FC-DenseNet -> Jegou et al 2017 (encoder-decoder models)
>>>Arranged in stacked configuration -> Newell et al 2016
>>Second
>>>Modified version of stacked hourglass model from Newell et al (2016)
>>>Possess hyperparameters that allow for changing of number of filters in each covolutional block to limit no. parameters
>>>Newell et all however use 256 filters for all layers 

>subpixel maxima motivation
>>for F-CNN posture estimation model, confidence maps must be converted into coordinate values
>>>Can be done by moving confidence maps outside of GPU and then processing them on CPU
>>>>Allows for easy accurate calculation of coordinates with subpixel precision (Insafutdinov)
>>>>Is not ideal as moving large arrays from GPU to CPU is not ideal, with CPU processes being more expensive
>>>Can also be done by processing confidence maps on GPU, then move coordinates from GPU to CPU
>>>>This requires confidence maps to be predicted at full resolution of input image or larger, slowing down inference speed

>subpixel maxima explanation
>>GPU based convolutional layer
>>Uses image registration algorithm introduced by Guizar-Sicairos et al. (2008)
>>>Translationally aligns two dimensional gaussian filter to each confidence map via Fourier based convolution 
>>>Allows for accurate prediction even if confidence maps are drmaatically smaller than resolution of input image
>>Even with confidence maps 1/8th resolution of original image, error did not drastically increase.
>>>Making predictions using confidence maps at downsampled resolution allows for faster inference >1000Hz

>Stacked DenseNet with subpixel Maxima
>>Real-time inference at ~30-110hz depending on resolution of confidence map
>>Faster than DeepLabCut for offline (100 batch) and real-time
>>Faster than LEAP for offline (100 batch)
>>Significantly slower than LEAP for real-time
>>Slower than stacked hourglass for offline
>>Significantly faster than stacked hourglass for real-time

>Multi-scalegeometry between keypoints improves accuracy
>>Minimizing prediction errors -> reduced affect on behavioural classification/analysis
>>Especially for analyses based on time-frequency transforms**
>>The effect of errors can be minimized using post-hoc** filters and smoothing but this loses high frequency information from time series data
>>Incorporating multiple spatial scales** (Chen et al. 2017) when making predictions can reduce errors


>Model output
>>Model has 4 layers of output
>>>Confidence map for smallest limb segments in graph
>>>confidence maps for individual limbs (left leg, right arm)
>>>Map with entire postural graph
>>>Fully integrated map that incorporates entire posture graph and confidence peaks for join locations
>>>Each level of hierarchical graph is built from lower levels of output, model learns correlated features across multiple scales

>Model evaluation I
>>Training Stacked DenseNet to predict hierarchical posture graph reduces keypoint error
>>Feature maps for posture graph removed from final output for inference, increasing prediction accuracy **WHY????????*
>>The error reduction from multi-scale geometry learning comes into full effect with datasets that have high image variance and sparse posture graphs
>>Predicting posture graph useful for animals with long appendages e.g. insect legs/antennae where prediction error likely to occur bc occlusions and natural variation in movement of these body parts.

>Model evaluation II 
>>Benchmarked vs LEAP & DeepLabCut
>>>Stacked DenseNet model outperforms LEAP and DLC in terms of speed and obtains higher accuracy than LEAP & Similar accuracy to DLC.
>>>Stacked DenseNet and Stacked Hourglass both outperformed LEAP.
>>>Stacked DenseNet models outperformed the LEAP model. 
>>>Stacked dense model 2X faster inference, 3X higher mean accuracy than LEAP
>>>Variance of predictions was lower, indicating models produced fewer extreme prediction error
>>>at 1/4 resolution Stacked DenseNet model achieved accuracy almost identeical to DLC while running inference at 2X speed, using ~5% of parameters, 1.5mil vs 26 mil
>>>Further reduction of resolution to 1/8th results in greater inference speed without much of an increase in error


>Model evaluation III
>>Stacked DenseNet(SDN) achieves good generalization without transfer learning
>>When combined with data augmentation, as few as 5 training examples can be used as a training set for labelling keypoints with active learning
>>Generalization to new data plateus after 100 training examples, so 100 examples becomes the minimum size for training set (with this value being dependant on variance of image data being annotated)
>>DLC use of transfer learning, pretraining model on ImageNet VS Randomly intialised weights, transfer learning provided very small improvement to its ability to generalize, a mean reduction in Euclidean error of <0.5 pixel.
>>SDN can be used for real time inference

>Motive
>>Therapy of mice
>>Measuring behavior is a critical factor for many studies in neuroscience (Krakauer et al., 2017).
>>Quantifying individual movement is essential for revealing the genetic(Kain et al., 2012; Brown et al., 2013; Ayroles et al., 2015) and environmental (Bierbach et al., 2017; Akhund-Zade et al., 2019; Versace et al., 2019) underpinnings of phenotypic variation in behavior


New pose estimation methods
>Replacing human annotatoins with fully articulated volumetrid 3D models of the animals body
>>SMAL model from Zuffi et al., 2017 or the SMALST model from Zuffi et al., 2019)



LEAP (Pereira et al 2019)
>Used active learning, for iteratively modifying training set.
>>Active learning: a trained model is uesd to initialize new training data, reducing annotation time
>Applied modified version of previous model -> SegNet (Badrinarayanan et al 2015)
>Attempts to limit model complexity, optimizing for inference speed.
>Not robust to data variance; rotations, shifts in lighting, different experimental setups
>Requires computationally expensive preprocessing **(PCA?)**
>Used for single pose estimation
>LEAP model has greater variance than DPK stacked hourglass model, suggesting its more prone to extreme prediction errors

DeepLapCut (Mathis et al 2018)
>Proposed techinques to refine training data and minimize error on testing
>> *Achieved through: Filtering data/selecting new training data based on **confidence scores or entropy of confidence maps** from model output.
>Applied a modified version of previous model -> DeeperCut(insafutdinov et al 2016)
>Built on ResNet Architecture(He et al 2016) (state of art used for image classif)
>>Allows for incorporating **pretrained encoder** to improve performance while reducing size of training set
>>Also known as **transfer learning** (Pratt 1992)
>>Transfer learning doesnt actually provide much improvement over random initialization
>>Pre trained architecture is overparameterized (>25mill params), allows for model to make accurate preds but results in slow inference
>>Mathis and Warren(2018) found inference speed can be improved by reducing resolution of input images, achieved at expense of accuracy
>Can do multiple pose estimation


General
>Mathis et al(2018), Pereira et al (2019) popularised use of CNN for animal pose estimation(APE)
>>Made use of F-CNN, often refferred to as encoder-decoder model. (Confidence maps)
>>Mathis and Pereira have both shown high accuracies can be achieved with small training set
>>Model generalised to large dataset by iteratively modifying training set

>Nath et al (2019) proposed temporal derivatives(speed,accleration) and autoregressive models to identify outlier frames
>>Outliers can then be labeled to refine training set or can be excluded

>Speed accuracy trade-off
>>DeepLabCut has an overparametrized model (high accuracy, slow inference)
>>LEAP uses smaller less robust model (Lower accuracy, less robust to varied data, quick inference) 

>LEAP achieves limited success in comparison to DeepLabCut

>F-CNN efficiency and robustness been improved via **multi-scale inference** (encoder-decoder models)
>>Allows model to integrate large-scale global information e.g. lighting, image background, anatomical geometry
>>Also allows for integration of local information e.g. differences in colour,texture, skin patterning etc

>Most multiple pose estimation havent solved tracking problem -> Linking individual posture data over frames in video
>>Multiple pose estimation requries annotation of multiple individuals, every individual in the image must be annotated to prevent model from learning conflicting information
>>More laborious than for single pose estimation, with labour increasing proportional to number of individuals in image

>Fast poes estimation using CNNs requires:
>>Large parallel processing on GPU with large bathces of data
>>Requires downsampling images to increase speed, which increases error (Mathias and Warren, 2018)
>>


Papers to read/Topics to read
>LEAP -> Pereira et al 2019 
>DeepLabCut -> Mathis et al 2019 
>ResNet -> Insafutdinov et al 2016 
>SegNet -> Badrinarayanan et al 2015 
>Papers on tracking
>>(PÃ©rez-Escudero et al., 2014; Crall et al., 2015; Graving, 2017; Romero-Ferrero et al., 2019; Wild et al., 2018; Boenisch et al., 2018)
>Individual pose estimation -> Newell et al 2016 
>Convolutional regression models (Encoder-Decoder models) -> Jegou et al 2017
>Conventional computer vision methods -> Guizar-Sicairos et al., 2008
>behaviour analysis (time frequency methods)
>> Berman et al. (2014b), Berman et al. (2016), Klibaite et al. (2017), Todd et al. (2017), Klibaite and Shaevitz (2019) and Pereira et al. (2019) 
>Improving CNN's outside of increased layers&connections
>>better loss functions (Goodfellow et al., 2014; Johnson et al., 2016a; Chen et al., 2017; Zhang et al., 2018)
>>models that more explicitly incorporate the spatial dependencies within a scene (Van den Oord et al., 2016b)
>>temporal structure of the data (Seethapathi et al., 2019)
>>as well as more mathematically principled approaches (e.g., Weigert et al., 2018; Roy et al., 2019) such as the application of formal probabilistic concepts (Kendall and Gal, 2017) and Bayesian inference at scale (Tran et al., 2018).

Topics to read up on 
>Encoder-Decoder Models 
>Confidence maps
>PCA
>Multiple pose estimation 
>Active learning
>Transfer learning
>Why is GPU processing quicker than CPU?
>Fourier based convolution
